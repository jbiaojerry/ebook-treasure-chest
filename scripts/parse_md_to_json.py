#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§£æ md ç›®å½•ä¸‹çš„æ‰€æœ‰ Markdown æ–‡ä»¶ï¼Œç”Ÿæˆç»Ÿä¸€çš„ JSON æ•°æ®æ–‡ä»¶
"""

import json
import re
from pathlib import Path
from collections import defaultdict

ROOT = Path(__file__).parent.parent
MD_DIR = ROOT / "md"
OUTPUT_JSON = ROOT / "docs" / "all-books.json"
STATS_FILE = ROOT / "docs" / "parse-stats.json"


def extract_category_from_file(file_path):
    """ä»æ–‡ä»¶è·¯å¾„æå–åˆ†ç±»å"""
    # ä»æ–‡ä»¶åæå–ï¼ˆå»æ‰ .md æ‰©å±•åï¼‰
    category = file_path.stem
    return category


def extract_category_from_content(content):
    """ä»æ–‡ä»¶å†…å®¹æå–åˆ†ç±»åï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
    # æŸ¥æ‰¾ # åˆ†ç±»å æ ¼å¼
    match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
    if match:
        # è·³è¿‡ç‰ˆæƒå£°æ˜ï¼Œæ‰¾ç¬¬äºŒä¸ª # æ ‡é¢˜
        lines = content.split('\n')
        for line in lines:
            if line.startswith('# ') and 'ç‰ˆæƒ' not in line and 'å£°æ˜' not in line:
                return line[2:].strip()
    return None


def parse_markdown_table(content):
    """è§£æ Markdown è¡¨æ ¼ï¼Œæå–ä¹¦ç±ä¿¡æ¯"""
    books = []
    lines = content.split('\n')
    
    # æ‰¾åˆ°è¡¨æ ¼å¼€å§‹ä½ç½®ï¼ˆåŒ…å« "ä¹¦å" çš„è¡Œï¼‰
    table_start = -1
    for i, line in enumerate(lines):
        if '| ä¹¦å' in line or 'ä¹¦å |' in line:
            table_start = i
            break
    
    if table_start == -1:
        return books
    
    # è·³è¿‡è¡¨å¤´åˆ†éš”è¡Œï¼ˆ---ï¼‰
    data_start = table_start + 2
    
    # è§£ææ•°æ®è¡Œ
    for i in range(data_start, len(lines)):
        line = lines[i].strip()
        if not line or not line.startswith('|'):
            continue
        
        # è§£æè¡¨æ ¼è¡Œï¼š| ä¹¦å | ä½œè€… | [ä¸‹è½½](é“¾æ¥) |
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
        pattern = r'\|\s*(.+?)\s*\|\s*(.+?)\s*\|\s*\[ä¸‹è½½\]\((.+?)\)\s*\|'
        match = re.match(pattern, line)
        
        if match:
            title = match.group(1).strip()
            author = match.group(2).strip()
            link = match.group(3).strip()
            
            # æ¸…ç†æ•°æ®
            title = title.replace('**', '').strip()
            author = author.replace('**', '').strip()
            
            if title and link:  # ç¡®ä¿æœ‰ä¹¦åå’Œé“¾æ¥
                books.append({
                    'title': title,
                    'author': author if author else 'æœªçŸ¥',
                    'link': link
                })
    
    return books


def parse_single_file(file_path):
    """è§£æå•ä¸ª Markdown æ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None, []
    
    # æå–åˆ†ç±»å
    category = extract_category_from_file(file_path)
    category_from_content = extract_category_from_content(content)
    
    # ä¼˜å…ˆä½¿ç”¨æ–‡ä»¶å†…å®¹ä¸­çš„åˆ†ç±»åï¼ˆæ›´å‡†ç¡®ï¼‰
    if category_from_content and category_from_content != category:
        category = category_from_content
    
    # è§£æè¡¨æ ¼
    books = parse_markdown_table(content)
    
    # ä¸ºæ¯æœ¬ä¹¦æ·»åŠ åˆ†ç±»ä¿¡æ¯
    for book in books:
        book['category'] = category
        # é»˜è®¤å€¼
        book['language'] = 'ZH'  # é»˜è®¤ä¸­æ–‡ï¼Œåç»­å¯ä¼˜åŒ–
        book['level'] = 'Unknown'
        book['formats'] = ['epub', 'mobi', 'azw3']  # ä»è¡¨æ ¼åˆ—åæ¨æ–­
    
    return category, books


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è§£æ md æ–‡ä»¶...")
    
    all_books = []
    category_stats = defaultdict(int)
    total_files = 0
    success_files = 0
    error_files = []
    
    # è·å–æ‰€æœ‰ md æ–‡ä»¶
    md_files = list(MD_DIR.glob("*.md"))
    total_files = len(md_files)
    
    print(f"ğŸ“ æ‰¾åˆ° {total_files} ä¸ª md æ–‡ä»¶")
    
    # è§£ææ¯ä¸ªæ–‡ä»¶
    for i, md_file in enumerate(md_files, 1):
        if i % 100 == 0:
            print(f"â³ å¤„ç†è¿›åº¦: {i}/{total_files} ({i*100//total_files}%)")
        
        category, books = parse_single_file(md_file)
        
        if category is None:
            error_files.append(str(md_file))
            continue
        
        if books:
            all_books.extend(books)
            category_stats[category] = len(books)
            success_files += 1
        else:
            error_files.append(str(md_file))
            print(f"âš ï¸  æœªæ‰¾åˆ°æ•°æ®: {md_file.name}")
    
    # ä¿å­˜ç»“æœ
    OUTPUT_JSON.parent.mkdir(exist_ok=True)
    
    print(f"\nğŸ“Š è§£æç»Ÿè®¡:")
    print(f"  - æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"  - æˆåŠŸè§£æ: {success_files}")
    print(f"  - å¤±è´¥æ–‡ä»¶: {len(error_files)}")
    print(f"  - æ€»ä¹¦ç±æ•°: {len(all_books)}")
    print(f"  - åˆ†ç±»æ•°é‡: {len(category_stats)}")
    
    # ä¿å­˜ JSON æ–‡ä»¶
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(all_books, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… JSON æ–‡ä»¶å·²ç”Ÿæˆ: {OUTPUT_JSON}")
    print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {OUTPUT_JSON.stat().st_size / 1024 / 1024:.2f} MB")
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_files': total_files,
        'success_files': success_files,
        'error_files': len(error_files),
        'total_books': len(all_books),
        'categories_count': len(category_stats),
        'top_categories': dict(sorted(category_stats.items(), key=lambda x: x[1], reverse=True)[:20]),
        'error_file_list': error_files[:10]  # åªä¿å­˜å‰10ä¸ªé”™è¯¯æ–‡ä»¶
    }
    
    with open(STATS_FILE, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {STATS_FILE}")
    
    # æ˜¾ç¤ºå‰10ä¸ªåˆ†ç±»
    print(f"\nğŸ† å‰10ä¸ªåˆ†ç±»ï¼ˆæŒ‰ä¹¦ç±æ•°é‡ï¼‰:")
    for cat, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"  - {cat}: {count} æœ¬")


if __name__ == "__main__":
    main()
