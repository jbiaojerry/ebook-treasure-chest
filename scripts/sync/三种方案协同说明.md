# 三种方案协同实现说明

## 📋 方案概述

为了确保大规模书籍同步（6万+书籍）的稳定性和可靠性，我们实现了三种互补的方案：

### ✅ 方案1：增加超时时间
- **状态**: ✅ 已实现
- **配置**: `timeout-minutes: 600` (10小时)
- **位置**: `.github/workflows/full-sync.yml`
- **作用**: 提供充足的超时时间，避免工作流被强制终止

### ✅ 方案2：断点续传功能
- **状态**: ✅ 已实现
- **机制**: 通过 `processed_ids.json` 记录已处理的ID
- **位置**: `scripts/sync/test_batch_sync.py`
- **作用**: 即使工作流中断，重新运行时会自动跳过已处理的书籍

### ✅ 方案3：分批处理功能
- **状态**: ✅ 已实现
- **参数**: `--batch-size` (例如: 20000)
- **位置**: `scripts/sync/sync_all_books.py`
- **作用**: 将大批量任务分成多个小批次，降低单次运行风险

---

## 🔄 三种方案如何协同工作

### 工作流程

```
开始全量同步
    ↓
方案1: 600分钟超时保护（最后保障）
    ↓
方案3: 分批处理（如果指定了 --batch-size）
    ├─ 批次1: ID 1-20000
    ├─ 批次2: ID 20001-40000
    ├─ 批次3: ID 40001-60000
    └─ 批次4: ID 60001-64970
    ↓
方案2: 断点续传（每个批次内部）
    ├─ 加载已处理的ID
    ├─ 跳过已处理的书籍
    └─ 只处理剩余的书籍
    ↓
完成同步
```

### 协同优势

1. **方案1 + 方案2**: 
   - 即使超时，断点续传可以继续处理
   - 双重保障，确保数据不丢失

2. **方案2 + 方案3**:
   - 每个批次内部都有断点续传
   - 批次间可以独立重试

3. **方案1 + 方案3**:
   - 每批次都有充足的超时时间
   - 降低单批次超时风险

4. **三种方案结合**:
   - 最强大的容错能力
   - 适合处理任意规模的同步任务

---

## 📖 使用示例

### 示例1：一次性处理（使用方案1+2）

```bash
# 一次性处理所有书籍，依赖超时保护和断点续传
python3 sync_all_books.py --max-id 64970 --skip-backup
```

**特点**:
- 简单直接
- 依赖600分钟超时保护
- 如果中断，断点续传会自动恢复

### 示例2：分批处理（使用方案1+2+3）

```bash
# 每批处理2万本书，共4批
python3 sync_all_books.py --max-id 64970 --skip-backup --batch-size 20000
```

**特点**:
- 更安全，每批独立
- 每批约33分钟（2万本 × 0.5秒/请求 ÷ 20并发 ÷ 60）
- 即使某批失败，其他批次不受影响

### 示例3：GitHub Actions 使用

```yaml
# .github/workflows/full-sync.yml
# 方案1: timeout-minutes: 600 (已配置)
# 方案2: 自动支持（代码已实现）
# 方案3: 可以通过修改命令添加 --batch-size
```

**当前配置**:
```yaml
python3 sync_all_books.py --skip-backup
```

**可选配置（启用分批处理）**:
```yaml
python3 sync_all_books.py --skip-backup --batch-size 20000
```

---

## 🎯 推荐策略

### 对于 6万+ 书籍的同步

**推荐配置**: 使用所有三种方案

```bash
python3 sync_all_books.py \
  --max-id 64970 \
  --skip-backup \
  --batch-size 20000
```

**优势**:
- ✅ 每批约33分钟，远低于600分钟超时
- ✅ 批次间有5秒暂停，避免压力过大
- ✅ 每批都有断点续传保护
- ✅ 即使某批失败，只需重试该批次

### 对于 2万以下 书籍的同步

**推荐配置**: 使用方案1+2即可

```bash
python3 sync_all_books.py --max-id 20000 --skip-backup
```

**优势**:
- ✅ 简单直接
- ✅ 预计时间约33分钟，远低于超时限制
- ✅ 断点续传提供额外保障

---

## 🔍 断点续传工作原理

### 数据存储

- **文件位置**: `md/processed_ids.json`
- **格式**: JSON 数组，包含所有已处理的书籍ID
- **更新时机**: 每批处理完成后自动更新

### 工作流程

```
1. 开始处理前
   ↓
2. 加载 processed_ids.json（如果存在）
   ↓
3. 过滤掉已处理的ID
   ↓
4. 只处理剩余的ID
   ↓
5. 处理完成后，保存新的已处理ID列表
```

### 示例

假设已处理了 ID 1-10000，然后中断：

```json
// md/processed_ids.json
[1, 2, 3, ..., 10000]
```

重新运行时：
- 自动加载已处理的ID
- 只处理 ID 10001-64970
- 完成后更新 processed_ids.json

---

## ⚙️ 参数说明

### sync_all_books.py 参数

| 参数 | 说明 | 默认值 | 示例 |
|------|------|--------|------|
| `--max-id` | 最大书籍ID | 自动查找 | `--max-id 64970` |
| `--start-id` | 起始书籍ID | 1 | `--start-id 10000` |
| `--batch-size` | 分批大小 | 无（一次性处理） | `--batch-size 20000` |
| `--skip-backup` | 跳过备份 | False | `--skip-backup` |
| `--skip-find-id` | 跳过查找ID | False | `--skip-find-id` |

### 使用建议

- **首次全量同步**: 使用 `--batch-size 20000` 分批处理
- **增量同步**: 不需要分批（数量较少）
- **恢复中断任务**: 直接重新运行，会自动断点续传

---

## 📊 性能估算

### 处理时间估算

基于配置：
- 并发数: 20
- 请求延迟: 0.5秒/请求
- 网络+解析时间: 约1.5-2秒/请求

**公式**:
```
批次时间 = (批次大小 ÷ 20并发) × 2秒
总时间 = 批次时间 × 批次数
```

**示例（64970本书，每批20000本）**:
- 批次1 (1-20000): (20000 ÷ 20) × 2 = 2000秒 ≈ 33分钟
- 批次2 (20001-40000): 33分钟
- 批次3 (40001-60000): 33分钟
- 批次4 (60001-64970): (4970 ÷ 20) × 2 = 497秒 ≈ 8分钟
- **总计**: 约107分钟 ≈ 1.8小时

---

## ✅ 总结

三种方案可以完美协同工作：

1. **方案1（超时保护）**: 提供最后的安全网
2. **方案2（断点续传）**: 确保数据不丢失
3. **方案3（分批处理）**: 降低单次运行风险

**推荐**: 对于大规模同步（6万+），同时使用三种方案，获得最强的容错能力。

---

**最后更新**: 2024年
